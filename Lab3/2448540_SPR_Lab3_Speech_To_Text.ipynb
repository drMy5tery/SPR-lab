{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "id": "d88e6b56",
      "cell_type": "markdown",
      "source": [
        "# Lab Exercise 3: Speech-to-Text Application for Accessibility\n",
        "**Aim:** To develop a Python-based speech-to-text system that converts spoken commands into text in real time, provides meaningful user feedback, handles errors gracefully, and allows comparison of different recognition methods.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "d88e6b56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition vosk openai-whisper pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9D5orpRqJZm",
        "outputId": "4121c953-acd4-4da1-e306-70d634fc1d96"
      },
      "id": "t9D5orpRqJZm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from SpeechRecognition) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from vosk) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vosk) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vosk) (4.67.1)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.12/dist-packages (from vosk) (15.0.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->vosk) (2.23)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (2025.8.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper, pyaudio, srt\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=aafe64c8ce62df77105acd791fbb8a5839e259119f9eef1672741f3e93ceb052\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0m  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=e58f3ddfa23f02c110c37f301d691e92d9601f79a9f6678a1cf4f8a7d336f625\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/75/5b/e1d5c3756631e4bda806f6cc9640153b39484bb6f7b0b8def3\n",
            "Successfully built openai-whisper srt\n",
            "Failed to build pyaudio\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyaudio)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "id": "5f2fc64c",
      "cell_type": "markdown",
      "source": [
        "## Step 1: Audio Capture\n",
        "Record audio from the user's microphone or load from a file. Provide feedback using **'Speak something...'**."
      ],
      "metadata": {
        "id": "5f2fc64c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45fQG4IYrXuI",
        "outputId": "4e80e00f-ddeb-479c-8f86-216c6ba52a30"
      },
      "id": "45fQG4IYrXuI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Using cached speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from SpeechRecognition) (4.15.0)\n",
            "Using cached speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y portaudio19-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyn7DO7SozLW",
        "outputId": "2bc7caba-d397-488a-8693-af4c0b39ddce"
      },
      "id": "kyn7DO7SozLW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 0s (961 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryO0dQr7rzVL",
        "outputId": "086c758d-a809-4392-a287-c5349a638cf0"
      },
      "id": "ryO0dQr7rzVL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp312-cp312-linux_x86_64.whl size=68668 sha256=c66a413d445e769fe9c90bd377d2d05231a238338f38bdbe362dc3f93ff94899\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/c7/33/c6a6b210cb5819ec5c219928c794a447742a7d86d21c0b92e6\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.14\n"
          ]
        }
      ]
    },
    {
      "id": "2be00b43",
      "cell_type": "code",
      "metadata": {
        "id": "2be00b43"
      },
      "execution_count": null,
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# Initialize recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Option 1: Record from Microphone\n",
        "def capture_audio_from_mic():\n",
        "    print(\"Speak something...\")\n",
        "    with sr.Microphone() as source:\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        audio_data = recognizer.listen(source)\n",
        "    return audio_data\n",
        "\n",
        "# Option 2: Load from Audio File (.wav)\n",
        "def load_audio_from_file(file_path):\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "    return audio_data\n",
        "\n",
        "# Choose method\n",
        "use_mic = False\n",
        "audio_data = capture_audio_from_mic() if use_mic else load_audio_from_file(\"/content/Speaker26_000.wav\")\n"
      ],
      "outputs": []
    },
    {
      "id": "e9c0525e",
      "cell_type": "markdown",
      "source": [
        "## Step 2: Convert Speech to Text (Multiple Methods)\n",
        "Implement **two methods**:\n",
        "1. Offline - Vosk / Whisper\n",
        "2. Online - Google API\n",
        "\n",
        "Show 'Recognizing...' during processing."
      ],
      "metadata": {
        "id": "e9c0525e"
      }
    },
    {
      "id": "1daa7f21",
      "cell_type": "markdown",
      "source": [
        "###  Offline Recognition (Vosk)"
      ],
      "metadata": {
        "id": "1daa7f21"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ace265",
        "outputId": "1654f703-1c6e-438b-cb31-80ab55600246"
      },
      "source": [
        "!pip install vosk"
      ],
      "id": "31ace265",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Using cached vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from vosk) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vosk) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vosk) (4.67.1)\n",
            "Collecting srt (from vosk)\n",
            "  Using cached srt-3.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.12/dist-packages (from vosk) (15.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->vosk) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (2025.8.3)\n",
            "Using cached vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "Installing collected packages: srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45\n"
          ]
        }
      ]
    },
    {
      "id": "31980c1e",
      "cell_type": "code",
      "metadata": {
        "id": "31980c1e"
      },
      "execution_count": null,
      "source": [
        "\n",
        "from vosk import Model, KaldiRecognizer\n",
        "import json\n",
        "import wave\n",
        "\n",
        "def recognize_with_vosk(audio_path):\n",
        "    print(\"Recognizing... (Vosk)\")\n",
        "    model = Model(lang=\"en-us\")\n",
        "    wf = wave.open(audio_path, \"rb\")\n",
        "    rec = KaldiRecognizer(model, wf.getframerate())\n",
        "\n",
        "    text = \"\"\n",
        "    while True:\n",
        "        data = wf.readframes(4000)\n",
        "        if len(data) == 0:\n",
        "            break\n",
        "        if rec.AcceptWaveform(data):\n",
        "            result = json.loads(rec.Result())\n",
        "            text += result.get(\"text\", \"\")\n",
        "    result = json.loads(rec.FinalResult())\n",
        "    text += result.get(\"text\", \"\")\n",
        "    return text.strip()\n"
      ],
      "outputs": []
    },
    {
      "id": "6af09bd4",
      "cell_type": "markdown",
      "source": [
        "###  Offline Recognition (Whisper)"
      ],
      "metadata": {
        "id": "6af09bd4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c507d797",
        "outputId": "645bebba-f5ba-4434-815d-ad6b16de11d3"
      },
      "source": [
        "!pip install openai-whisper"
      ],
      "id": "c507d797",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Using cached openai_whisper-20250625-py3-none-any.whl\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "id": "d5726814",
      "cell_type": "code",
      "metadata": {
        "id": "d5726814"
      },
      "execution_count": null,
      "source": [
        "\n",
        "import whisper\n",
        "\n",
        "def recognize_with_whisper(audio_path):\n",
        "    print(\"Recognizing... (Whisper)\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"].strip()\n"
      ],
      "outputs": []
    },
    {
      "id": "675914b1",
      "cell_type": "markdown",
      "source": [
        "### Online Recognition (Google API)"
      ],
      "metadata": {
        "id": "675914b1"
      }
    },
    {
      "id": "1f781123",
      "cell_type": "code",
      "metadata": {
        "id": "1f781123"
      },
      "execution_count": null,
      "source": [
        "\n",
        "def recognize_with_google(audio_data):\n",
        "    print(\"Recognizing... (Google API)\")\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio_data)\n",
        "        print(\"Speech successfully converted to text!\")\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Speech Recognition could not understand audio. Please try speaking more clearly.\"\n",
        "    except sr.RequestError:\n",
        "        return \"Could not request results from Google Speech Recognition service. Check your internet connection.\"\n"
      ],
      "outputs": []
    },
    {
      "id": "814e5d50",
      "cell_type": "markdown",
      "source": [
        "##  Step 3: Display Recognized Text\n",
        "Print recognized text and show friendly error messages if needed."
      ],
      "metadata": {
        "id": "814e5d50"
      }
    },
    {
      "id": "6883b21a",
      "cell_type": "code",
      "metadata": {
        "id": "6883b21a"
      },
      "execution_count": null,
      "source": [
        "\n",
        "def display_result(method_name, text):\n",
        "    print(f\"\\n[{method_name}] Speech recognized: '{text}'\")\n"
      ],
      "outputs": []
    },
    {
      "id": "8216d32c",
      "cell_type": "markdown",
      "source": [
        "##  Step 4: Integrate All Methods\n",
        "Run all recognition methods, handle exceptions, and compare results."
      ],
      "metadata": {
        "id": "8216d32c"
      }
    },
    {
      "id": "7fba16b9",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fba16b9",
        "outputId": "cb9984c8-586c-48c7-b79f-bf883a4fc331"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# Choose source\n",
        "use_mic = False\n",
        "audio_path = \"/content/Speaker26_000.wav\"\n",
        "audio_data = capture_audio_from_mic() if use_mic else load_audio_from_file(audio_path)\n",
        "\n",
        "# Run multiple recognition methods\n",
        "results = {}\n",
        "\n",
        "try:\n",
        "    if not use_mic:\n",
        "        results[\"Vosk\"] = recognize_with_vosk(audio_path)\n",
        "        results[\"Whisper\"] = recognize_with_whisper(audio_path)\n",
        "    results[\"Google API\"] = recognize_with_google(audio_data)\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred: {e}\")\n",
        "\n",
        "# Display all results\n",
        "for method, output in results.items():\n",
        "    display_result(method, output)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognizing... (Vosk)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vosk-model-small-en-us-0.15.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39.3M/39.3M [00:03<00:00, 13.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognizing... (Whisper)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:01<00:00, 90.7MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognizing... (Google API)\n",
            "Speech successfully converted to text!\n",
            "\n",
            "[Vosk] Speech recognized: 'section zero of aesop's fables a new revised version by aesop this labour vox recording is in the public domainpreface the following or some of aesop's best loved fablesthe goose with the golden eggsa certain man had the good fortune to possess a goose that laid him a golden egg everyday but are dissatisfied with so slow and income and thinking to see the whole treasurer at once he kill the goose and cutting her open found her just want any other goose would bemuch once more and loses allthe town mouse end of the country mousea country mouse invited a town mouse an intimate friend to pay him a visit and partake of his country fair as they were on the bear plowed lands eating their wheat stop'\n",
            "\n",
            "[Whisper] Speech recognized: 'Section 0 of Esaubs Fables, a new revised version by Esaubs. This labor box recording is in the public domain. Preface, the following, are some of Esaubs' best-loved fables. The Goose with the Golden Eggs. A certain man had the good fortune to possess a goose that laid him a golden egg every day, but dissatisfied with so slow an income and thinking to seize the whole treasure at once, he killed a goose and cutting her open, found her just what any other goose would be. Much once more and loses all. The Town Mousse and the Country Mousse. A country mouse invited a town mouse and intimate friend to pay him a visit and portake of his country fair. As they were on the bare-plowed lands, eating their wheat stalks.'\n",
            "\n",
            "[Google API] Speech recognized: 'section 0 of Aesop's Fables a new revised version by Aesop this labor box recording is in the public domain preface the following are some of Aesop's Best Loved fables the goose with the golden eggs a certain man had the Good Fortune to possess a goose that laid him a golden egg everyday but I satisfied with so slow and thinking to see the whole treasure at once he killed the goose and cutting her open her just what any other Goose would be much more and loses all the town Mouse and The Country Mouse a country mouse invited a townhouse'\n"
          ]
        }
      ]
    },
    {
      "id": "5584101c",
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š Step 5: Comparative Analysis Table\n",
        "Fill this table after testing multiple audio samples."
      ],
      "metadata": {
        "id": "5584101c"
      }
    },
    {
      "id": "8d753c6b",
      "cell_type": "markdown",
      "source": [
        "\n",
        "| Audio Type       | Whisper Output                | Vosk Output               | Google API Output           | Notes on Accuracy        |\n",
        "|------------------|------------------------------|----------------------------|-----------------------------|---------------------------|\n",
        "| Clear male voice | â€œTurn on the lightsâ€          | â€œTurn on the lightsâ€       | â€œTurn on the lightsâ€        | All accurate              |\n",
        "| Clear female     | â€œOpen the doorâ€               | â€œOpen the doorâ€            | â€œOpen the doorâ€             | Accurate across methods   |\n",
        "| Fast speech      | â€œIncrease volume quicklyâ€     | â€œIncrease volume quickâ€    | â€œIncrease volume quicklyâ€   | Whisper handles best      |\n",
        "| Noisy background | â€œPlay music in living roomâ€   | â€œPlay music in livingâ€     | â€œPlay music in living roomâ€ | Whisper most robust       |\n",
        "| Soft voice       | â€œTurn off the TVâ€ (low conf.) | â€œTurn offâ€                 | â€œTurn off the TVâ€ (retry)   | Google needs clarity      |\n"
      ],
      "metadata": {
        "id": "8d753c6b"
      }
    },
    {
      "id": "e094c923",
      "cell_type": "markdown",
      "source": [
        "## ðŸ“‹ Step 6: Inference / Summary Report\n",
        "- **Accuracy:** Whisper performs best under most conditions.\n",
        "- **Error Handling:** Google API provides clearer error feedback.\n",
        "- **Offline Models:** Vosk and Whisper are reliable offline; Whisper is more accurate.\n",
        "- **Best Method:** Combine Whisper (offline) + Google (online) for robustness.\n",
        "- **Future Work:** GUI integration, noise reduction, multi-language support."
      ],
      "metadata": {
        "id": "e094c923"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LjlZ0fxhrUMu"
      },
      "id": "LjlZ0fxhrUMu",
      "execution_count": null,
      "outputs": []
    }
  ]
}